{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM+Zu0/1ifPtqfTA8I0FQpg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vRxjdAM1emzP",
        "outputId": "e1ca6dae-042a-4938-c05d-09fa2b8b9d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1ulGMPJeKjT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "af9a8dbf-e30c-4b6b-a15b-2901e2169a4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from einops import einsum\n",
        "from datasets import load_dataset\n",
        "from accelerate.test_utils.testing import get_backend\n",
        "\n",
        "DEVICE, _, _ = get_backend()\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"ylecun/mnist\")"
      ],
      "metadata": {
        "id": "jHPh2zzUoNkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_to_tensor(image):\n",
        "    return torchvision.transforms.functional.to_tensor(image).to(DEVICE)"
      ],
      "metadata": {
        "id": "n1XstVfAzSMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im = image_to_tensor(ds[\"train\"][0][\"image\"])\n",
        "im.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHhe-kJ8e6hk",
        "outputId": "b342f2d2-422c-491f-f6e8-342be7fb487d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, X, W, b):\n",
        "        ctx.save_for_backward(X, W)\n",
        "        out_features = einsum(X, W, \"b h_in, h_in h_out -> b h_out\")\n",
        "        return out_features + b.unsqueeze(0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        (X, W) = ctx.saved_tensors\n",
        "        grad_input = einsum(W, grad_output, \"h_in h_out, b h_out -> b h_in\")\n",
        "        grad_W = einsum(X, grad_output, \"b h_in, b h_out -> h_in h_out\")\n",
        "        grad_b = einsum(grad_output, \"b h_out -> h_out\")\n",
        "        return grad_input, grad_W, grad_b\n",
        "\n",
        "class LinearModule(torch.nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "        self.W = torch.nn.Parameter(torch.empty((in_features, out_features)))\n",
        "        self.b = torch.nn.Parameter(torch.empty(out_features))\n",
        "\n",
        "        torch.nn.init.normal_(self.W)\n",
        "        torch.nn.init.normal_(self.b)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return LinearFunction.apply(X, self.W, self.b)"
      ],
      "metadata": {
        "id": "OMs8M9l4AgQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(1, 32, 5),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Conv2d(32, 64, 5),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Flatten(),\n",
        "    # nn.Linear(1024, 512),\n",
        "    LinearModule(1024, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.25),\n",
        "    # nn.Linear(512, 10)\n",
        "    LinearModule(512, 10)\n",
        ")\n",
        "model.to(DEVICE)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQPO3haEnKBE",
        "outputId": "67a54f46-c0a1-4812-d172-7d5a3d707650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (1): ReLU()\n",
              "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (4): ReLU()\n",
              "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (6): Flatten(start_dim=1, end_dim=-1)\n",
              "  (7): LinearModule()\n",
              "  (8): ReLU()\n",
              "  (9): Dropout(p=0.25, inplace=False)\n",
              "  (10): LinearModule()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NJasEg2Dzhq",
        "outputId": "29fc3fd1-1c15-4383-d94b-0f74155b4bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.weight torch.Size([32, 1, 5, 5])\n",
            "0.bias torch.Size([32])\n",
            "3.weight torch.Size([64, 32, 5, 5])\n",
            "3.bias torch.Size([64])\n",
            "7.W torch.Size([1024, 512])\n",
            "7.b torch.Size([512])\n",
            "10.W torch.Size([512, 10])\n",
            "10.b torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_params = 0\n",
        "for parameter in model.parameters():\n",
        "    num_params += np.prod(parameter.shape)\n",
        "num_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwiQPvoosVdV",
        "outputId": "09240a90-0b2f-4299-f0a0-86e375870571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(582026)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetWrapper:\n",
        "    def __init__(self, dataset, batch_size):\n",
        "        self.ds = dataset.to_iterable_dataset()\n",
        "        self.batch_size = batch_size\n",
        "        self.dataset_length = len(dataset)\n",
        "        self.iterations = (len(dataset) + batch_size - 1) // batch_size\n",
        "\n",
        "    def shuffle(self):\n",
        "        self.ds = self.ds.shuffle()"
      ],
      "metadata": {
        "id": "ClFGK1McC9wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_reference(logits):\n",
        "    return F.softmax(logits, dim=-1)\n",
        "\n",
        "def softmax(logits):\n",
        "    return logits.exp() / (logits.exp().sum(dim=-1, keepdim=True))"
      ],
      "metadata": {
        "id": "LE-4qIx0kdGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdamW:\n",
        "    def __init__(self,\n",
        "                 params,\n",
        "                 lr=0.001,\n",
        "                 betas=(0.9, 0.999),\n",
        "                 eps=1e-08,\n",
        "                 weight_decay=0.01):\n",
        "        self.params = [param for param in params]\n",
        "        self.lr = lr\n",
        "        self.b1, self.b2 = betas\n",
        "        self.eps = eps\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "        self.ms = [torch.zeros_like(param) for param in self.params]\n",
        "        self.vs = [torch.zeros_like(param) for param in self.params]\n",
        "\n",
        "    def step(self):\n",
        "        for param, m, v in zip(self.params, self.ms, self.vs):\n",
        "            param.data.sub_(self.lr * self.weight_decay * param.data)\n",
        "            m.mul_(self.b1).add_((1 - self.b1) * param.grad)\n",
        "            v.mul_(self.b2).add_((1 - self.b2) * param.grad**2)\n",
        "            m_corr = m / (1 - self.b1)\n",
        "            v_corr = v / (1 - self.b2)\n",
        "            param.data.sub_(self.lr * m_corr / (v_corr**0.5 + self.eps))\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for param in self.params:\n",
        "            param.grad = None\n"
      ],
      "metadata": {
        "id": "FpZQdutKrON6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_reference(logits, labels):\n",
        "    return F.cross_entropy(logits, labels, reduction=\"mean\")\n",
        "\n",
        "def cross_entropy(logits, labels):\n",
        "    pred_logits = logits[torch.arange(logits.shape[0]), labels]\n",
        "    logprobs = pred_logits - torch.logsumexp(logits, dim=-1)\n",
        "    return -logprobs.mean()\n",
        "\n",
        "def images_to_tensor_batch(images):\n",
        "    return torch.cat([\n",
        "        image_to_tensor(image)\n",
        "        for image in images\n",
        "    ]).unsqueeze(1)\n",
        "\n",
        "def labels_to_tensor_batch(labels):\n",
        "    return torch.LongTensor(labels).to(DEVICE)\n",
        "\n",
        "def train_one_batch(model, optimizer, batch):\n",
        "    images = images_to_tensor_batch(batch[\"image\"])\n",
        "    labels = labels_to_tensor_batch(batch[\"label\"])\n",
        "\n",
        "    logits = model(images)\n",
        "\n",
        "    loss = cross_entropy(logits, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "def train_one_epoch(model, optimizer, wrapped_ds):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for batch in tqdm(wrapped_ds.ds.iter(batch_size=wrapped_ds.batch_size),\n",
        "                      total=wrapped_ds.iterations):\n",
        "        loss = train_one_batch(model, optimizer, batch)\n",
        "        losses.append(loss)\n",
        "    return losses\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, wrapped_ds):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    for batch in tqdm(wrapped_ds.ds.iter(batch_size=wrapped_ds.batch_size),\n",
        "                    total=wrapped_ds.iterations):\n",
        "        images = images_to_tensor_batch(batch[\"image\"])\n",
        "        labels = labels_to_tensor_batch(batch[\"label\"])\n",
        "\n",
        "        logits = model(images)\n",
        "        pred = logits.argmax(dim=-1)\n",
        "\n",
        "        loss = cross_entropy(logits, labels)\n",
        "        accuracy = (pred == labels).sum().item() / len(labels)\n",
        "        losses.append(loss.item())\n",
        "        accuracies.append(accuracy)\n",
        "    return losses, accuracies\n",
        "\n",
        "wrapped_train = DatasetWrapper(ds[\"train\"], batch_size=64)\n",
        "wrapped_test = DatasetWrapper(ds[\"test\"], batch_size=64)\n",
        "# optimizer = torch.optim.AdamW(model.parameters())\n",
        "optimizer = AdamW(model.parameters())\n",
        "for epoch in range(2):\n",
        "    print(f\"Epoch {epoch + 1}\")\n",
        "    losses = train_one_epoch(model, optimizer, wrapped_train)\n",
        "    print(\"Average train loss: \", np.mean(losses))\n",
        "    test_losses, test_accuracies = evaluate(model, wrapped_test)\n",
        "    print(\"Average eval loss: \", np.mean(test_losses))\n",
        "    print(\"Average eval accuracy: \", np.mean(test_accuracies))\n",
        "    wrapped_train.shuffle()\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV3u-YketfIv",
        "outputId": "e4985eef-4816-453f-ecca-02ceed4b6c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:13<00:00, 67.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average train loss:  2.6954755883640065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:02<00:00, 73.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average eval loss:  0.3678508244312493\n",
            "Average eval accuracy:  0.9670581210191083\n",
            "\n",
            "Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:16<00:00, 58.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average train loss:  0.7219443577550241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 98.97it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average eval loss:  0.21402439593699327\n",
            "Average eval accuracy:  0.9783041401273885\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}